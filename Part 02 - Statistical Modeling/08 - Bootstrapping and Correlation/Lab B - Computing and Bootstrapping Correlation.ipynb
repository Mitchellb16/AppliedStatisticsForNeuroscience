{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/HWNI_logo.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab B - Computing and Bootstrapping Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes our plots show up in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import util.utils as utils\n",
    "import util.shared as shared\n",
    "\n",
    "shared.format_plots()\n",
    "shared.format_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's generate some correlated data.\n",
    "\n",
    "The simplest way to generate data that is dependent is to first sample one set of random numbers, then generate another set whose values depend on the first. \n",
    "\n",
    "In this example, we create correlated data by first sampling an array of x values from a standard normal and then generating an array of ys by adding another set of random numbers to the xs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50\n",
    "noise_level = 2\n",
    "\n",
    "def generate_data(num_points, noise_level):\n",
    "    xs = np.random.standard_normal(size=num_points)\n",
    "    ys = np.asarray([x+np.random.standard_normal()*noise_level\n",
    "                     for x in xs])\n",
    "    \n",
    "    return xs,ys\n",
    "\n",
    "xs,ys = generate_data(num_points,noise_level)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(xs, ys,\n",
    "            s=24,linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python offers a number of options for computing the correlation coefficient of two or more datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy offers the `corrcoef` function. This function returns a correlation matrix -- the `ij`th entries of this matrix tell you the correlation between the `i`th and `j`th arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 What do you expect the correlation coefficient to be when `i == j` (i.e. for the diagonal elements of the matrix)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `corrcoef` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the `noise_level` above.\n",
    "\n",
    "#### Q2 What happens to the  correlation coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers a way to calculate the correlation matrix of the numeric columns in a data frame. Data frames have a method, `.corr` that returns the correlation matrix as a data frame.\n",
    "\n",
    "First, we have to get our data into the pandas `DataFrame` format. Do this in a cell below using `pd.DataFrame.from_dict` or `.from_items`, then calculate the correlation matrix using `data.corr()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template:\n",
    "```python\n",
    "df = pd.DataFrame.from_dict({'?':?,\n",
    "                            '?':?})\n",
    "df.corr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn's prime directive is to make things that people do frequently as painless as possible. Since plotting pairs of things and calculating their correlation is a very common step in data analysis, seaborn makes it extremely easy.\n",
    "\n",
    "Use the function `sns.jointplot` to simultaneously make a scatter plot of the data, calculate the correlation coefficient, and get a bootstrapped $p$-value for the correlation (it's easier than it sounds -- check the tutorial for details!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template:\n",
    "```python\n",
    "sns.jointplot(data=?, x=?, y=?)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By \"Hand\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discussed a formula for the correlation coefficient, $r$. It is reproduced below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r = \\frac{1}{n-1} \\sum_{i=1}^{n}{\\frac{(x_i-\\mu_x)}{s_x}\n",
    "                                  \\frac{(y_i-\\mu_y)}{s_y}}\n",
    "$$\n",
    "\n",
    "where $s_a$ is the estimated population standard deviation of a variable $a$:\n",
    "\n",
    "$$\n",
    "s_a = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n}{\\left(a_i-\\mu_a\\right)^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtracting the mean and dividing by the standard deviation is known as \"standard scoring\" or \"$z$-scoring\".\n",
    "\n",
    "Use this formula to define a function that will compute the correlation coefficient of any pair of random variables, then run that function on our data.\n",
    "You might be interested in the functions `np.mean` and `np.std`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template:\n",
    "```python\n",
    "def correlate(xs, ys):\n",
    "    z_scored_xs = z_score(xs)\n",
    "    z_scored_ys = z_score(ys)\n",
    "    return np.dot(?,?)/(?)\n",
    "\n",
    "def z_score(xs):\n",
    "    mu = ?\n",
    "    sd = np.std(?, ddof=?)\n",
    "    zs = [(x - ?)/? for x in xs]\n",
    "    return zs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Confidence Intervals on Correlations with Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first half of the lab, we examined the bootstrapping procedure for estimating the sampling distribution of statistics. Now, we'll use that procedure to estimate the sampling distribution of the correlation coefficient.\n",
    "\n",
    "In the cell below, implement the bootstrap for the correlation coefficient. That is, generate a dataset of size $N$ (aka `num_points`). Then, draw $N$ pairs of `x` and `y` values from the dataset (with replacement) and calculate the correlation coefficient. You can use `np.random.randint(0, len(data))` to generate a random list of indices for sampling with replacement, as shown in the tutorial. Draw pairs from the same dataset at least 1000 times and then plot the distribution of the resulting values with `sns.distplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50\n",
    "noise_level = 2\n",
    "\n",
    "xs,ys = generate_data(num_points, noise_level)\n",
    "\n",
    "data = np.asarray([xs, ys]).T #this format is more convenient for bootstrapping\n",
    "num_bootstraps = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template:\n",
    "```python\n",
    "def bootstrap_sample(data):\n",
    "    # draw N pairs of x and y values\n",
    "    indices = np.random.randint(0, len(data), size=?)\n",
    "    return data[indices].T\n",
    "\n",
    "def run_bootstrap(data, num_bootstraps):\n",
    "    # use bootstrap_sample num_bootstraps times,\n",
    "    # computing the correlation coefficient each time\n",
    "    rs = np.zeros(num_bootstraps)\n",
    "    for bootstrap_idx in range(num_bootstraps):\n",
    "        sample = bootstrap_sample(data)\n",
    "        rs[bootstrap_idx] = np.corrcoef(?)[0,1]\n",
    "    return rs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = run_bootstrap(data, num_bootstraps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given (an approximation to) the sampling distribution, we can calculate a confidence interval at confidence level $1 - \\alpha$ by dropping the extreme values of the sampling distribution -- the lower bound of the confidence interval is the $\\alpha/2$th percentile of the sampled values and the upper bound of the confidence interval is the $1-\\alpha/2$th percentile.\n",
    "\n",
    "Compute the confidence interval for your correlation coefficient in the cell below. Use, as we do out of habit, $\\alpha=0.05$. You might want to look up `np.percentile`. Notice that it takes percentiles as values between 0 and 100, not between 0 and 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template:\n",
    "```python\n",
    "def compute_CI(rs, alpha=.05):\n",
    "    CI = [np.percentile(rs, 100*?),\n",
    "          np.percentile(rs, 100*(1-?))]\n",
    "    return CI\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correlate(xs, ys))\n",
    "compute_CI(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can compute a confidence interval, we can compute a $p$-value.\n",
    "\n",
    "#### Q3 Briefly, how would you check if a result is significant at a level $\\alpha$ using the set of sampled $r$s?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "neur299",
   "language": "python",
   "name": "neur299"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
