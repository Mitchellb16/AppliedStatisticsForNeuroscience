{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/HWNI_logo.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - One-Way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes our plots show up inside Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import util.utils as utils\n",
    "import util.shared as shared\n",
    "\n",
    "shared.format_plots()\n",
    "shared.format_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this week's lab, we'll be using some EEG data graciously provided by the [Voytek lab](http://voyteklab.com/about-us/) of UCSD. Participants of varying ages were asked to perform a working memory task with varying levels of difficulty. The raw EEG signal has been summarized into the following two measures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Contralateral Delay Activity](https://www.ncbi.nlm.nih.gov/pubmed/26802451), or CDA, is used to measure the engagement of visual working memory.\n",
    "\n",
    "* [Frontal Midline Theta](https://www.ncbi.nlm.nih.gov/pubmed/9895201) oscillation amplitude has been correlated with sustained, internally-directed cognitive activity.\n",
    "\n",
    "The performance of the subjects has also been summarized using the measure\n",
    "[d'](https://en.wikipedia.org/wiki/Sensitivity_index) (pronounced \"d-prime\"), also known as the *sensitivity index*. D' is a measure of the subject's performance in  a task. It's based on comparing the true positive rate and false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data and take a look at a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/voytek_working_memory_aging_split.csv',index_col=None)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this lab, we're interested only in how task difficulty affects our three measures. We're uninterested in the subject's metadata -- `age_split`, `group`, `age`, and `idx`. Let's begin by dropping those columns from our dataframe using the DataFrame method `drop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['age_split','group','age','idx'], axis=1)\n",
    "data[data.id == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good practice to keep an original copy of your dataframe around (here, named `df`) so you can undo irreversible changes, like dropping columns.\n",
    "\n",
    "If we're interested in looking at subject-by-subject information, we're not quite done with formatting our data. For subject-level analysis, our data is not yet tidy, since a single subject's observations are scattered over multiple rows. Use the `pivot` method to tidy our data. Hint: we want to get our row `index`es from the subject's `id` and to make new `columns` for our measures using the level of `difficulty`. Look back at the last lab (Lab B) for an example of using `pivot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data = data.pivot(index='id', columns='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It now takes two pieces of information to pick out a particular column: the measure we're interested in (one of `d`, `cda`, or `fmt`) and the `difficulty` level: `1`, `2`, or `3`. These need to be provided in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = 'cda'\n",
    "difficulty = 2\n",
    "\n",
    "pivot_data[measure, difficulty].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead only index into the first level, we get a single-level dataframe back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data[measure].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll be running ANOVA using difficulty as an independent factor and the three measures as dependent factors. Choose a visualization or collection of visualizations that you think would be appropriate for this purpose and plot the data below. Be ready to explain your choice in class.\n",
    "\n",
    "You can use either the `pivot`ed data frame or the un`pivot`ed data frame.\n",
    "\n",
    "Hint: the easiest way to apply most of our visualizations to this dataset is to write a loop that runs over our measures and produces a separate plot for each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template:\n",
    "```python\n",
    "for measure in [\"cda\",\"fmt\",\"d\"]:\n",
    "    plt.figure()\n",
    "    data = pivot_data[measure]\n",
    "    sns.?\n",
    "    ...\n",
    "    plt.title(measure+\" versus difficulty\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the assumptions behind ANOVA.\n",
    "\n",
    "#### Q1 Based off of your visualization, do you think any of the assumptions of ANOVA are being violated for the case of fmt? What about d'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-In Tools for ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `scipy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll use the built-in `scipy.stats` function `f_oneway` to perform One-Way ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.f_oneway?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to organize the code you write in the cell below so that you minimize the amount you repeat yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow-Up $t$-Tests\n",
    "\n",
    "Select a measure with a significant ANOVA result and take a look at the data as you plotted it above.\n",
    "\n",
    "It's often tempting to conclude on the basis of the ANOVA result\n",
    "that any pattern we see or don't see in the data must be \"real\",\n",
    "i.e. reflect a statistically significant result.\n",
    "\n",
    "For example, on the measure `cda`,\n",
    "we might be tempted to conclude that difficulty levels 2 and 3\n",
    "are significantly different from difficulty level 1.\n",
    "\n",
    "But a significant ANOVA result does not make a statement about\n",
    "which levels of the factor are different from each other;\n",
    "instead, it only says that the levels are somehow different.\n",
    "\n",
    "To determine where the effect is coming from,\n",
    "we need to perform follow-up $t$-tests\n",
    "where we compare the means of two factor levels directly.\n",
    "These tests will help us determine which inter-group differences are statistically significant.\n",
    "\n",
    "In the cell below,\n",
    "use `scipy.stats.ttest_ind`\n",
    "(which we learned about in the two-sample testing lab)\n",
    "to perform follow-up $t$-tests comparing\n",
    "the contralateral delay activity, `cda`,\n",
    "across difficulty levels -- 1 vs 2, 2 vs 3, and 1 vs 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 What are your results? Are they different from what you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering what the point of the initial ANOVA was,\n",
    "given that we needed to run additional statistical testing in order to determine our results.\n",
    "Why not just go straight to the $t$-tests?\n",
    "\n",
    "As mentioned in the tutorial for this section,\n",
    "ANOVA first tests the null hypothesis that\n",
    "all of the groups means are the same as the grand mean.\n",
    "If we reject this null hypothesis only if $p < \\alpha$,\n",
    "then we know that the familywise error rate\n",
    "for our follow-up $t$-tests can't be greater than $\\alpha$,\n",
    "since, if the null hypothesis is true,\n",
    "we only perform them with probability $\\alpha$.\n",
    "\n",
    "Put less technically,\n",
    "the initial ANOVA provides \"cover\" for our follow-up $t$-tests,\n",
    "eliminating our multiple comparisons problem\n",
    "by controlling the familywise error rate for the combined statistical test \"ANOVA plus $t$-tests\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`statsmodels`](http://www.statsmodels.org/stable/index.html)\n",
    "is a Python package that implements\n",
    "a number of popular features from the statistical computing language\n",
    "[R](https://www.r-project.org/about.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into how to use statsmodels,\n",
    "we need to note that there are two equivalent ways of viewing the ANOVA.\n",
    "In one view,\n",
    "the ANOVA is a statistical test related to the $t$-test\n",
    "but for more complicated experiments.\n",
    "In the other view,\n",
    "the ANOVA is a test of how well the data is explained\n",
    "by the implicit linear model.\n",
    "We have focused on the former view of ANOVA.\n",
    "\n",
    "While there are interfaces for running ANOVA in R\n",
    "that use the framework we've focused on,\n",
    "there are not any stable,\n",
    "mature packages for Python that implement\n",
    "ANOVA in this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead,\n",
    "these packages,\n",
    "including statsmodels,\n",
    "implement ANOVA as a two step process:\n",
    "\n",
    "1. Fit the implicit linear model\n",
    "1. Test the goodness-of-fit of that model.\n",
    "\n",
    "Models are described,\n",
    "as they are in R packages that use the same framework,\n",
    "using *formula strings*.\n",
    "These are short strings that specify\n",
    "which columns of a dataframe are observations\n",
    "and which columns are factors.\n",
    "\n",
    "The formula functionality\n",
    "of statsmodels\n",
    "is complex enough that it\n",
    "is imported separately\n",
    "from the rest of statsmodels,\n",
    "just like `scipy.stats`\n",
    "is a separate import from `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a One-Way ANOVA,\n",
    "the formula string is simple:\n",
    "\n",
    "`'observation ~ factor'`\n",
    "\n",
    "with one extra complication.\n",
    "These formulas can describe models with mixtures of\n",
    "categorical variables,\n",
    "like our `difficulty` variable,\n",
    "and numerical variables,\n",
    "like our `age` variable.\n",
    "If a categorical variable is coded as a number,\n",
    "like our `difficulty` variable,\n",
    "then we have to tell statsmodels\n",
    "that the numbers in that variable should be treated as\n",
    "category labels.\n",
    "We do this by putting the variable's name inside a\n",
    "`C()`,\n",
    "like so:\n",
    "\n",
    "`'observation ~ C(categorical_factor)'`\n",
    "\n",
    "The statsmodels approach may seem like a lot of extra work,\n",
    "especially compared to the scipy option.\n",
    "However, this extra complexity is what\n",
    "allows statsmodels to represent very complicated ANOVAs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below runs a One-Way ANOVA for the `cda` measure.\n",
    "Compare the results to the output of `f_oneway` for this measure,\n",
    "then change the formula to get the results for each of the other two measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'cda ~ C(difficulty)'\n",
    "\n",
    "ols_lm = smf.ols(formula, data=data)\n",
    "\n",
    "fit = ols_lm.fit()\n",
    "\n",
    "table = sm.stats.anova_lm(fit, typ=2)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many folks find it easier to work with ANOVAs\n",
    "in the formulation we used previously,\n",
    "ANOVA as a hypothesis test,\n",
    "rather than this new formulation,\n",
    "ANOVA as a goodness-of-fit test for a model.\n",
    "If that's the case for you,\n",
    "and you need to run fairly complex ANOVAs,\n",
    "then Python is not a good choice for this problem.\n",
    "\n",
    "There are numerous packages for the R language\n",
    "that implement ANOVA in different ways.\n",
    "To learn more about R,\n",
    "check out the awesome tutorials on\n",
    "[R-tutor](http://www.r-tutor.com/).\n",
    "\n",
    "But that doesn't mean you need to completely drop Python!\n",
    "It's possible to\n",
    "[run R scripts from inside Python](https://www.r-bloggers.com/integrating-python-and-r-part-ii-executing-r-from-python-and-vice-versa/),\n",
    "which allows you to keep the rest of your analysis and visualization work in Python,\n",
    "while running ANOVAs in R.\n",
    "We won't go into more detail about this approach in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing Up ANOVA by Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the\n",
    "[tutorial](./Tutorial - ANOVA by Hand.ipynb),\n",
    "we walked through how to calculate the $F$-statistic by hand.\n",
    "The code from that lab is conveniently wrapped up in the `utils` as\n",
    "`anova_by_hand`, which returns the\n",
    "`anova_frame`, the three dictionaries we used to calculate the $F$ value,\n",
    "and $F$ itself.\n",
    "\n",
    "Now, we'll add on the last few steps of an ANOVA:\n",
    "determining the $p$-value\n",
    "and reporting effect size with $\\eta^2$ and $\\omega^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = \"cda\"\n",
    "\n",
    "anova_frame, sum_of_squares, dof, mean_square, F  = utils.anova_by_hand(data, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret this $F$ value and so determine if the amount of variance we were able to explain is close to what one would expect by chance, we need to get a hold of the sampling distribution of the $F$-statistic under the null hypothesis. Once we have that, we can calculate the area under the curve from the observed value on up and use that to determine our $p$-value.\n",
    "\n",
    "#### Q3 Why do we only calculate a \"one-tailed\" area, above our value, rather than a \"two-tailed\" area? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two options for acquiring the sampling distribution of $F$:\n",
    "\n",
    "1. Use a pre-calculated distribution. In the old days, that'd mean looking up values in a table in a reference text. These days, statistical computing libraries like `scipy` provide this service via functions.\n",
    "1. Simulate what our data would look like under the null hypothesis and use the distribution of the $F$-statistic from our simulations to approximate the true distribution of $F$\n",
    "\n",
    "We'll take the second road.\n",
    "This will involve a\n",
    "[*resampling*](https://en.wikipedia.org/wiki/Resampling_%28statistics%29) technique called an\n",
    "[*approximate permutation test*](https://en.wikipedia.org/wiki/Resampling_%28statistics%29#Monte_Carlo_testing).\n",
    "It is closely related to\n",
    "[exact tests](https://en.wikipedia.org/wiki/Exact_test).\n",
    "\n",
    "We discussed approximate permutation tests in the section on hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4 Explain, in your own words, what the null hypothesis of the ANOVA test is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5 Under the null hypothesis of ANOVA, what can we say about the relationship between the group label and the measurement? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6 Based on this relationship, how could we simulate what our data would look like under the null hypothesis? That is, how could we generate data that is distributed according to the null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `utils.estimate_f_distribution` will implement this simulation and then compare the results to the true null sampling distribution of $F$, provided by `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = \"cda\"\n",
    "groups = data.difficulty.unique()\n",
    "\n",
    "grouped_data = utils.group_data(pivot_data,measure,groups)\n",
    "\n",
    "Fs = utils.estimate_F_distribution(grouped_data)\n",
    "\n",
    "sorted_Fs = sorted(Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "utils.plot_approximated_F(Fs)\n",
    "utils.plot_true_F(dof[\"explained\"], dof[\"residual\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate an approximate $p$-value for the value of $F$ calculated above by subtracting one from the empirical cumulative density function of the `sorted_Fs` evaluated at the observed value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7 Explain why subtracting one from the empirical CDF of the statistic under the null distribution evaluated at the observed value gives the $p$-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below checks that the answers given by this method and by `scipy` are in agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eCDF(F, sorted_Fs):\n",
    "    try:\n",
    "        index = np.where(sorted_Fs > F)[0][0] #returns a tuple of arrays, we want first element of first array\n",
    "    except IndexError:\n",
    "        index = len(sorted_Fs)\n",
    "        \n",
    "    return index/len(sorted_Fs)\n",
    "\n",
    "approx_p = 1-eCDF(F, sorted_Fs)\n",
    "       \n",
    "_, scipy_p = run_ANOVA(pivot_data, measure)\n",
    "       \n",
    "(scipy_p - approx_p)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the process of generating our estimated $F$ distribution, we need to generate a bunch of data sets that are distributed according to the null hypothesis. We can use these, plus any method that calculates $p$-values, to simulate the distribution of $p$-values under the null hypothesis. The function `utils.simulate_null` will do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = utils.simulate_null(grouped_data, N=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8 What sampling distribution do we expect the $p$-value to have under the null hypothesis? How might this distribution look different under the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, plot the simulated sampling distribution of the $p$-value. You'll want `sns.distplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ps, bins=np.arange(-0.25,1.3,0.05), kde=False,\n",
    "             hist_kws={'histtype':'stepfilled',\n",
    "                       'density':True,\n",
    "                       'linewidth':4,\n",
    "                       'edgecolor':'gray',\n",
    "                       'alpha':0.8}, label =r\"Null Distribution of $p$\");\n",
    "plt.ylim([0, 1.5])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond $p$ - Effect Size Reporting with $\\eta^2$ and $\\omega^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $F$-statistic is used to determine the statistical significance of an ANOVA result.\n",
    "\n",
    "Recall that previously, we've distinguished between practical/scientific and statistical significance. Statistical significance is centered around whether an effect exists at all.\n",
    "\n",
    "#### Q9 How is this different from the practical or scientific significance of an ANOVA result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The APA recommends that, in addition to reporting $F$ and $p$, scientists report the value $\\eta^2$, which is equal to the ratio of the explained sum-of-squares to the explainable sum-of-squares. It's also known as the *variance explained*.\n",
    "\n",
    "#### Q10 Why is this number closer to a notion of practical significance than $F$ is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $\\eta^2$ for a statistically significant test you ran above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11 Does this seem like a practically significant fraction to you? Look back at the visualizations of the data you produced at the beginning of the lab. Are there any visual hints that would lead you to expect a value of $\\eta^2$ close to what you calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that $\\eta^2$ uses the sums-of-squares, rather than mean squares.\n",
    "This means that it doesn't take into account degrees of freedom\n",
    "and is therefore a biased estimator of the quantity it is trying to capture:\n",
    "it overestimates how much variance has been explained.\n",
    "Intuitively, it only captures how well you explained your dataset,\n",
    "not how well you might explain additional data from the same population.\n",
    "\n",
    "An unbiased estimator for explained variance exists, known as $\\omega^2$ (pronounced \"omega-squared\"). You can [read more about it here](http://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html).\n",
    "\n",
    "Use the following formula to compute $\\omega^2$ for your test:\n",
    "\n",
    "$$\n",
    "    \\omega^2 = \\frac{F-1}{\\frac{F+1+\\text{df}_{residual}}{\\text{df}_{explained}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template:\n",
    "```python\n",
    "om_sqrd = ?/(?/?)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12 Does this more accurate estimate change your opinion of the the practical significance of the results of your test?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
