{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/HWNI_logo.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes our plots appear inside Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import util.utils as utils\n",
    "import util.shared as shared\n",
    "\n",
    "shared.format_plots()\n",
    "shared.format_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we use simulated experiments to investigate the ideas covered in the\n",
    "[tutorial on Hypothesis Testing](./Tutorial\\ -\\ Hypothesis\\ Testing.ipynb).\n",
    "\n",
    "The experiment we simulate is inspired by a \n",
    "[classic neuroscience experiment](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1514868/)\n",
    "performed by Adrian in the 1920s.\n",
    "\n",
    "At the time, very little of what we now take for granted was known about the behavior of neurons. This early experiment demonstrated that the nerves exiting the cat's foot produced more action potentials when a weight was pressed onto the foot in a manner that depended on the weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/adrian_yngve_1926_apparatus.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll model this experiment using the random number generators provided with NumPy. The function `run_experiment` below will produce a random spike count using the\n",
    "[Poisson](https://en.wikipedia.org/wiki/Poisson_distribution)\n",
    "distribution, which has been used to\n",
    "[model neural spiking in response to stimuli](https://en.wikipedia.org/wiki/Linear-nonlinear-Poisson_cascade_model),\n",
    "then compare it to the argument `critical_value`.\n",
    "The result of the test is returned as number:\n",
    "`0` if the alternative hypothesis is not accepted\n",
    "and `1` if the alternative hypothesis is accepted.\n",
    "If the random spike count is higher than the critical value,\n",
    "the alternative hypothesis is accepted,\n",
    "otherwise it is not accepted.\n",
    "\n",
    "The average value of the random spike count is determined by a parameter.\n",
    "This parameter is set by two of the arguments to `run_experiment`: `baserate`, which we can think of as setting the average number of spikes when the foot is not being stimulated, and `difference`, which corresponds to the change in this average when the foot is stimulated.\n",
    "\n",
    "This is a very simple experiment and a very simple statistical test, but it will still allow us to see the major features of hypothesis testing discussed in the tutorial:\n",
    "true positive rates, false positive rates, and false discovery rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general hypothesis testing terms, the *test statistic* we are using is just the value of the data point that we observed. We might call the measurements from the unstimulated foot the *control measurements* and the measurement from the stimulated foot the *experimental measurement*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(baserate, difference, critical_value):\n",
    "    \"\"\" run a single experiment where the number of spikes recorded from a \n",
    "        neuron firing with rate baserate+difference\n",
    "        is compared to the critical_value.\n",
    "        \n",
    "        returns a 1 if the (randomly-generated) number of spikes\n",
    "        is higher than the cutoff, otherwise returns a 0\n",
    "        \n",
    "        the number of spikes comes from a poisson distribution\n",
    "    \"\"\"\n",
    "    stimulated_spikes = np.random.poisson(lam=baserate+difference)\n",
    "    \n",
    "    if stimulated_spikes > critical_value:\n",
    "        accepted = 1\n",
    "    else:\n",
    "        accepted = 0\n",
    "    \n",
    "    return accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_experiments(num_experiments, rate, effect_size, critical_value):\n",
    "    \"\"\" simulate num_experiments experiments with run_experiment\n",
    "        and return the result as a list.\n",
    "        \n",
    "        this list has 1s where the null hypothesis was rejected\n",
    "        and 0s where the null hypothesis was not rejected\n",
    "    \"\"\"\n",
    "    results = np.zeros(num_experiments)\n",
    "    \n",
    "    for experiment_idx in range(num_experiments):\n",
    "        result = run_experiment(rate, effect_size, critical_value)\n",
    "        results[experiment_idx] = result\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True and False Positive Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll estimate the true and false positive rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 In your own words, what are true and false positive rates? What's the difference between a false positive rate and a false discovery rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can estimate the false positive rate by simulating the results of our hypothesis test when the effect size, the difference in average spike counts between stimulated and unstimulated nerves, is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 What is the connection between the effect size being 0 and the false positive rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the experiments are stored in a list called `nulltrue_results`. Each element is either a `1` or ` 0`, depending on whether the alternative hypothesis was accepted or not. Use this list to calculate the fraction of times that we got a (false) positive result. You could use a `for` loop or the `sum` function or the `np.mean` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 10\n",
    "effect_size = 0\n",
    "\n",
    "critical_value = 15\n",
    "num_experiments = 1000\n",
    "\n",
    "nulltrue_results = simulate_experiments(num_experiments, rate, effect_size,\n",
    "                                       critical_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The false positive rate depends critically (ha!) on the critical value of our test. Remember that the critical value is the value of the test statistic (for us, this is just the observed spike count) above which you reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3 Make a prediction: will increasing the critical value increase or decrease the false positive rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your prediction in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 10\n",
    "effect_size = 0\n",
    "\n",
    "critical_value = 17\n",
    "num_experiments = 1000\n",
    "\n",
    "nulltrue_results_higher_crit_value = simulate_experiments(num_experiments, rate, effect_size,\n",
    "                                       critical_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, changing the critical value changes the false positive rate. The two code cells below will allow us to examine this dependence in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4 Make a prediction: what will the false positive rate be when the critical value is 0? what about when the critical value is very large?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first cell below calculates the rate of false positives for experiments with a range of critical values and stores them in a list called `false_positive_rates`.\n",
    "\n",
    "The cell beneath it will then plot the resulting false positive rates as a function of the critical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "false_positive_rates = []\n",
    "\n",
    "rate = 10\n",
    "effect_size = 0\n",
    "num_experiments = 100000\n",
    "\n",
    "critical_values = range(0,21)\n",
    "\n",
    "for critical_value in critical_values:\n",
    "    nulltrue_results = simulate_experiments(num_experiments, rate, 0,\n",
    "                                       critical_value)\n",
    "    \n",
    "    false_positive_rates.append(np.mean(nulltrue_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_rates(critical_values, false_positive_rates, \"False Positive Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can estimate the true positive rate by simulating the results of our hypothesis test when the effect size is non-zero.\n",
    "\n",
    "The cell below will produce a list, `nullfalse_results`, just like the `nulltrue_results` list from above. Use it to calculate the true positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 10\n",
    "effect_size = 1\n",
    "\n",
    "critical_value = 15\n",
    "num_experiments = 10000\n",
    "\n",
    "nullfalse_results = simulate_experiments(num_experiments, rate, effect_size,\n",
    "                                       critical_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true positive rate depends, just like the false positive rate, on the critical value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4 Make a prediction: will increasing the critical value increase or decrease the true positive rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your prediction using the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 10\n",
    "effect_size = 1\n",
    "\n",
    "critical_value = 17\n",
    "num_experiments = 1000\n",
    "\n",
    "nullfalse_results = simulate_experiments(num_experiments, rate, effect_size,\n",
    "                                       critical_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, we can simulate the results for a variety of critical values. The two cells below calculate and then plot the true positive rate with varying critical values. For comparison, the false positive rate is also plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_positive_rates = []\n",
    "\n",
    "rate = 10\n",
    "effect_size = 1\n",
    "num_experiments = 100000\n",
    "\n",
    "critical_values = range(0,21)\n",
    "\n",
    "for critical_value in critical_values:\n",
    "    nullfalse_results = simulate_experiments(num_experiments, rate, effect_size,\n",
    "                                       critical_value)\n",
    "    \n",
    "    true_positive_rates.append(np.mean(nullfalse_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_true_and_false_positive_rates(critical_values,\n",
    "                                         false_positive_rates,\n",
    "                                         true_positive_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5 Based on this chart, what would you select as your critical value? There is no single correct answer. Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPR as a Function of Critical Value and Effect Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true positive rate also depends on the actual size of the effect you're looking for.\n",
    "\n",
    "The code cells below will produce an interactive 3-d plot of the true positive rate as a function of both the effect size and the critical value. Left-clicking and dragging allows you to rotate the plot, while right-clicking and dragging allows you to zoom.\n",
    "\n",
    "These interactive features are enabled by the `%matplotlib notebook` magic. **If the plot doesn't show up the first time you run the cell, run it again**.\n",
    "\n",
    "Once you're done with this plot, run the cell underneath it, containing the `%matplotlib inline magic`, to return plots to their normal, non-interactive forms. You can also run the first code cell (the one with all of the imports)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baserate = 10\n",
    "\n",
    "num_experiments = 10000\n",
    "\n",
    "critical_values = list(range(5,21))\n",
    "effect_sizes = list(range(1,16))\n",
    "\n",
    "TPR = utils.estimate_TPR(baserate, effect_sizes, critical_values, simulate_experiments,\n",
    "                         num_experiments=num_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "shared.format_plots()\n",
    "\n",
    "utils.plot_TPR(critical_values, effect_sizes, TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "shared.format_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6 Explain the shape of this graph: why does the rate go down when you decrease the effect size and hold the critical value constant? why are the extreme values -- closest to 1 (blue) and closest to 0 (red) -- located where they are?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7 Why can't we calculate a true positive rate for the case where `effect_size == 0`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p$-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a good model of our null hypothesis, then we do more than just say whether we reject or fail to reject the null. If we can determine the probability that, if the null hypothesis were true, we'd observe what we observed, then we can express the degree to which our results support the null hypothesis. This probability is called the $p$-value.\n",
    "\n",
    "In many familiar statistical tests, this model is *parametric* -- we assume some form for the distribution of the data, and therefore the test statistic, under the null hypothesis and then, possibly after measuring some data generated according to the null hypothesis and inferring those parameters, we use the mathematical form of that distribution to calculate the $p$-value.\n",
    "\n",
    "When we don't know what form to assume the null distribution has, we can use a *nonparametric* method instead. In a non-parametric method, we instead use the data measurements to directly estimate the shape of the null distribution of the test statistic. Since our test statistic is just the number of spikes that we measure in a single experiment, that means we just need to collect a large number of spike counts distributed according to the null hypothesis.\n",
    "\n",
    "So in our case, we estimate the $p$-value by repeatedly measuring the spike counts from a neuron in an unstimulated cat's foot and then calculating how often that spike count is higher than the spike count from the neuron when the foot is stimulated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will simulate measuring the spike counts from an unstimulated foot `number_null_measurements` times, along with a single measurement of the spike count from a stimulated foot.\n",
    "\n",
    "It then plots a histogram of the spike counts from the unstimulated foot along with a single tick mark indicating the number of spikes measured from the stimulated foot. The bins are selected so that each bin contains a single value of the spike count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_null_measurements = 10000\n",
    "\n",
    "difference = 5\n",
    "baserate = 10\n",
    "\n",
    "null_spikes = np.random.poisson(lam=baserate,size=10000)\n",
    "experiment_spikes = np.random.poisson(lam=baserate+difference)\n",
    "\n",
    "utils.plot_null_and_result(null_spikes, experiment_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8 What is the relationship between this histogram and the null distribution of our test statistic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rough guess for the $p$-value can be read directly off the chart above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9 Explain how you'd do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the $p$-value precisely, we need the actual heights for this histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10 How would we calculate the $p$-value from this information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below uses the function `np.histogram` to collect these values and store them in the list `probabilities`. This list acts like a probability mass function: accessing the `i`th element of the list with `probabilities[i]` tells you the fraction of experiments in which `i` spikes occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = utils.get_bins(null_spikes,experiment_spikes)\n",
    "\n",
    "probabilities, bin_edges = np.histogram(null_spikes, bins=bins, normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the $p$-value in the cell below.\n",
    "\n",
    "*Hint:* things you might use include: `for` loops, `if` statements amd the `np.sum` function.\n",
    "Also: `list[i:]` will return all the values in a list from the `i`th element to the end of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate a different outcome for the experiment by running the cell below to collect a different random value for `stimulated_spikes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_spikes = np.random.poisson(lam=baserate+difference)\n",
    "utils.plot_null_and_result(null_spikes, experiment_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11 Re-calculate the $p$-value. Is it the same or different? Why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the probability distribution, the *cumulative distribution function* can be used to represent the chance that a random variable, like a test statistic, takes on some value. The cumulative distribution function, also known as the CDF, takes in a value and returns the probability that the random variable is *less than or equal to* that value. Put another way, it tells you how much probability has *accumulated* as the value of the random variable increases from some minimum up to the current value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below calculates and plots the cumulative distribution function for the null distribution of our test statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12 How might this information be used to calculate the $p$-value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDF, new_edges = utils.make_CDF(probabilities, bin_edges)\n",
    "utils.plot_CDF(CDF, new_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the $p$-value is the probability, under the null hypothesis, that the test statistic takes on a value that is at least as extreme as the measured value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q13 Based on this, can you determine the chance, when the null hypothesis is true, that the $p$-value is less than 0.5? 0.05? 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to our simulation framework, we can answer this question directly. The cell below will compute the $p$-value for a large number of experiments and then present the histogram of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baserate = 1000\n",
    "null_spikes = np.random.poisson(lam=baserate,size=100000)\n",
    "bins = utils.get_bins(null_spikes,baserate+baserate)\n",
    "\n",
    "probabilities, bin_edges = np.histogram(null_spikes, bins=bins, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_experiments = 10000\n",
    "effect_size = 1\n",
    "\n",
    "CDF, new_edges = utils.make_CDF(probabilities, bin_edges)\n",
    "\n",
    "ps = [1 - CDF(experiment_spikes) for experiment_spikes \n",
    "                        in np.random.poisson(lam=baserate+effect_size,size=num_experiments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.plot_p_distribution(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q14 What shape does this distribution have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell above with the `effect_size` set to `10`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q15 Now what shape does the distribution have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information about the shape of the distribution of $p$-values can be used to calculate false discovery rates, but only if we run a variety of very similar experiments. For more, see this\n",
    "[Points of Significance article](http://www.nature.com/nmeth/journal/v11/n4/full/nmeth.2900.html)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "neur299",
   "language": "python",
   "name": "neur299"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
